"""
Script to read and analyze telemetry HDF5 files generated by Level0_5 processing.

This script provides utilities to:
- Read telemetry HDF5 files
- Access telemetry data as numpy structured arrays
- Query specific fields and packet types
- Get metadata about the telemetry data
"""

import h5py
import numpy as np
import os
import argparse
from pathlib import Path
import matplotlib.pyplot as plt


class TelemetryReader:
    """Class to read and work with telemetry HDF5 files."""
    
    def __init__(self, filepath):
        """
        Initialize the telemetry reader.
        
        Args:
            filepath (str): Path to the telemetry HDF5 file
        """
        if not os.path.exists(filepath):
            raise FileNotFoundError(f"Telemetry file not found: {filepath}")
        
        self.filepath = filepath
        self.file = h5py.File(filepath, 'r')
        
        # Detect format: new columnar format has 'timestamp_seconds_since_boot' as a dataset
        # Old format has a structured array dataset named 'telemetry' or 'dsps'
        if 'timestamp_seconds_since_boot' in self.file:
            # New columnar format
            self.format = 'columnar'
            self.num_packets = len(self.file['timestamp_seconds_since_boot'])
        else:
            # Old structured array format (for backward compatibility)
            self.format = 'structured'
            self.data_type = 'telemetry'  # Default, will be detected if different
            
            # Detect the dataset name (could be 'telemetry' or 'dsps')
            if 'telemetry' in self.file:
                self.data_type = 'telemetry'
            elif 'dsps' in self.file:
                self.data_type = 'dsps'
            else:
                # Try to find any dataset
                keys = list(self.file.keys())
                if keys:
                    self.data_type = keys[0]
                    print(f"Warning: Using dataset '{self.data_type}' (expected 'telemetry' or 'dsps')")
                else:
                    raise ValueError("No datasets found in HDF5 file")
            
            self.dataset = self.file[self.data_type]
            self.data_array = self.dataset[:]  # Load the structured array
            self.num_packets = len(self.data_array)
        
    def __enter__(self):
        """Context manager entry."""
        return self
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        """Context manager exit - close the file."""
        self.close()
    
    def close(self):
        """Close the HDF5 file."""
        if self.file:
            self.file.close()
    
    def get_field_names(self):
        """
        Get all field names (keywords) in the telemetry data.
        
        Returns:
            list: Field names (all datasets except special ones)
        """
        if self.format == 'columnar':
            # Get all dataset names, excluding special ones
            all_keys = list(self.file.keys())
            special_keys = ['timestamp_seconds_since_boot', 'packet_type']
            return [key for key in all_keys if key not in special_keys]
        else:
            # Old format
            return list(self.data_array.dtype.names) if self.data_array.dtype.names else []
    
    def get_metadata(self):
        """
        Get metadata stored in the HDF5 file.
        
        Returns:
            dict: Dictionary of metadata attributes
        """
        metadata = {}
        
        # File-level attributes
        for key in self.file.attrs:
            metadata[key] = self.file.attrs[key]
        
        # Dataset-level attributes (only for old format)
        if self.format == 'structured':
            for key in self.dataset.attrs:
                metadata[f'dataset_{key}'] = self.dataset.attrs[key]
        
        return metadata
    
    def get_field(self, field_name):
        """
        Get a specific field from the telemetry data.
        
        Args:
            field_name (str): Name of the field to retrieve
            
        Returns:
            numpy.ndarray: Array of values for the specified field
        """
        if self.format == 'columnar':
            if field_name not in self.file:
                raise ValueError(f"Field '{field_name}' not found. Available fields: {self.get_field_names()}")
            return self.file[field_name][:]
        else:
            # Old format
            if field_name not in self.data_array.dtype.names:
                raise ValueError(f"Field '{field_name}' not found. Available fields: {self.get_field_names()}")
            return self.data_array[field_name]
    
    def get_packet_types(self):
        """
        Get unique packet types in the telemetry data.
        
        Returns:
            numpy.ndarray: Array of unique packet type names
        """
        if self.format == 'columnar':
            packet_types = self.file['packet_type'][:]
            # Convert bytes to strings and get unique values
            packet_types_str = np.array([pt.decode('utf-8').strip() if isinstance(pt, bytes) 
                                        else str(pt).strip() for pt in packet_types])
            return np.unique(packet_types_str)
        else:
            return np.unique(self.data_array['packet_type'])
    
    def filter_by_packet_type(self, packet_type, case_sensitive=False):
        """
        Filter telemetry data by packet type.
        
        Args:
            packet_type (str or bytes): Packet type to filter by
            case_sensitive (bool): Whether comparison should be case-sensitive (default: False)
            
        Returns:
            dict or numpy.ndarray: Filtered data (dict for columnar format, array for structured)
        """
        # Convert to string for comparison
        if isinstance(packet_type, bytes):
            packet_type_str = packet_type.decode('utf-8').strip()
        else:
            packet_type_str = packet_type.strip()
        
        if not case_sensitive:
            packet_type_str = packet_type_str.lower()
        
        if self.format == 'columnar':
            # Get packet types and create mask
            packet_types_in_data = self.file['packet_type'][:]
            packet_types_str = np.array([pt.decode('utf-8').strip() if isinstance(pt, bytes) 
                                        else str(pt).strip() 
                                        for pt in packet_types_in_data])
            
            if not case_sensitive:
                packet_types_str = np.array([pt.lower() for pt in packet_types_str])
            
            mask = packet_types_str == packet_type_str
            
            # Return a dictionary-like object with all fields filtered
            filtered_data = {}
            for field_name in self.get_field_names():
                filtered_data[field_name] = self.file[field_name][:][mask]
            # Also include timestamp and packet_type
            filtered_data['timestamp_seconds_since_boot'] = self.file['timestamp_seconds_since_boot'][:][mask]
            filtered_data['packet_type'] = self.file['packet_type'][:][mask]
            
            # Create a simple object that acts like a structured array
            class FilteredData:
                def __init__(self, data_dict, mask):
                    self.data_dict = data_dict
                    self.mask = mask
                    self.dtype = type('dtype', (), {'names': list(data_dict.keys())})()
                
                def __len__(self):
                    return np.sum(self.mask)
                
                def __getitem__(self, key):
                    if isinstance(key, str):
                        return self.data_dict[key]
                    else:
                        # Index access - return a dict for that row
                        indices = np.where(self.mask)[0]
                        if isinstance(key, int):
                            idx = indices[key]
                            return {k: v[idx] if isinstance(v, np.ndarray) else v 
                                   for k, v in self.data_dict.items()}
                        else:
                            # Slice
                            return {k: v[indices[key]] for k, v in self.data_dict.items()}
            
            return FilteredData(filtered_data, mask)
        else:
            # Old format
            packet_types_in_data = self.data_array['packet_type']
            packet_types_str = np.array([pt.decode('utf-8').strip() if isinstance(pt, bytes) 
                                        else str(pt).strip() 
                                        for pt in packet_types_in_data])
            
            if not case_sensitive:
                packet_types_str = np.array([pt.lower() for pt in packet_types_str])
            
            mask = packet_types_str == packet_type_str
            return self.data_array[mask]
    
    def find_fields_containing(self, substring, case_sensitive=False):
        """
        Find field names containing a substring (e.g., 'temp' for temperature).
        
        Args:
            substring (str): Substring to search for
            case_sensitive (bool): Whether search should be case-sensitive
            
        Returns:
            list: List of field names containing the substring
        """
        field_names = self.get_field_names()
        if case_sensitive:
            return [name for name in field_names if substring in name]
        else:
            return [name for name in field_names if substring.lower() in name.lower()]
    
    def get_timestamps(self):
        """
        Get all timestamps from the telemetry data.
        
        Returns:
            numpy.ndarray: Array of timestamps
        """
        if self.format == 'columnar':
            return self.file['timestamp_seconds_since_boot'][:]
        else:
            return self.data_array['timestamp_seconds_since_boot']
    
    def get_summary(self):
        """
        Print a summary of the telemetry data.
        """
        print(f"\n=== Telemetry File Summary ===")
        print(f"File: {self.filepath}")
        print(f"Format: {self.format}")
        if self.format == 'structured':
            print(f"Dataset: {self.data_type}")
        print(f"\nMetadata:")
        metadata = self.get_metadata()
        for key, value in metadata.items():
            print(f"  {key}: {value}")
        
        print(f"\nData Statistics:")
        print(f"  Total packets: {self.num_packets}")
        timestamps = self.get_timestamps()
        print(f"  Time range: {timestamps.min():.2f} to {timestamps.max():.2f} seconds")
        
        print(f"\nPacket Types:")
        packet_types = self.get_packet_types()
        if self.format == 'columnar':
            packet_type_data = self.file['packet_type'][:]
            # Convert all to strings for comparison
            packet_type_data_str = np.array([pt.decode('utf-8').strip() if isinstance(pt, bytes) 
                                            else str(pt).strip() for pt in packet_type_data])
            for ptype in packet_types:
                count = np.sum(packet_type_data_str == ptype)
                print(f"  {ptype}: {count}")
        else:
            for ptype in packet_types:
                count = np.sum(self.data_array['packet_type'] == ptype)
                print(f"  {ptype.decode('utf-8') if isinstance(ptype, bytes) else ptype}: {count}")
        
        print(f"\nAvailable Fields ({len(self.get_field_names())} total):")
        field_names = self.get_field_names()
        for i, field in enumerate(field_names):
            if i < 10:  # Show first 10
                print(f"  {field}")
            elif i == 10:
                print(f"  ... and {len(field_names) - 10} more")
                break


def main():
    """Main function for command-line usage."""
    parser = argparse.ArgumentParser(description='Read and analyze telemetry HDF5 files')
    parser.add_argument('filepath', type=str, nargs='?', 
                       default='/Users/masonjp2/Dropbox/suncet_dropbox/9000 Processing/data/test_data/2026-01-16_7170-002_fm_flatsat_cpt/2026_016_09_23_06_FM_FLATSAT_CPT/telemetry/suncet_telemetry_mission_length_v1.0.0.h5',
                       help='Path to telemetry HDF5 file')
    parser.add_argument('--summary', action='store_true', help='Print summary of telemetry data')
    parser.add_argument('--fields', action='store_true', help='List all field names')
    parser.add_argument('--search', type=str, help='Search for fields containing substring (e.g., "temp")')
    parser.add_argument('--packet-type', type=str, help='Filter by packet type')
    parser.add_argument('--field', type=str, help='Get values for a specific field')
    parser.add_argument('--examples', action='store_true', help='Run example usage demonstrations')
    
    args = parser.parse_args()
    
    # If --examples flag is used, run example code
    if args.examples:
        filepath = args.filepath
        print("=" * 70)
        print("EXAMPLE USAGE OF TelemetryReader")
        print("=" * 70)
        
        with TelemetryReader(filepath) as reader:
            # Example 1: Get summary
            print("\n[Example 1] Getting summary of telemetry data:")
            print("-" * 70)
            reader.get_summary()
            
            # Example 2: Find temperature fields
            print("\n[Example 2] Finding temperature-related fields:")
            print("-" * 70)
            temp_fields = reader.find_fields_containing('temp')
            print(f"Found {len(temp_fields)} temperature fields:")
            for field in temp_fields:
                print(f"  - {field}")
            
            # Example 3: Get a specific field
            if 'ana_cdh_temp' in reader.get_field_names():
                print("\n[Example 3] Accessing 'ana_cdh_temp' field:")
                print("-" * 70)
                temps = reader.get_field('ana_cdh_temp')
                print(f"Shape: {temps.shape}")
                print(f"Non-NaN values: {np.sum(~np.isnan(temps))}")
                print(f"Min: {np.nanmin(temps):.2f}")
                print(f"Max: {np.nanmax(temps):.2f}")
                print(f"Mean: {np.nanmean(temps):.2f}")
                print(f"First 10 values: {temps[:10]}")
            
            # Example 4: Filter by packet type
            print("\n[Example 4] Filtering by packet type 'beacon':")
            print("-" * 70)
            beacon_data = reader.filter_by_packet_type('beacon')
            print(f"Found {len(beacon_data)} beacon packets")
            if len(beacon_data) > 0:
                # Get available fields (works for both formats)
                if hasattr(beacon_data, 'dtype') and hasattr(beacon_data.dtype, 'names'):
                    available_fields = beacon_data.dtype.names
                else:
                    # Columnar format - get from data_dict
                    available_fields = list(beacon_data.data_dict.keys())
                print(f"Available fields: {available_fields}")
                if 'beac_time_since_boot' in available_fields:
                    times = beacon_data['beac_time_since_boot']
                    print(f"Non-NaN time values: {np.sum(~np.isnan(times))}")
            
            # Example 5: Get all packet types
            print("\n[Example 5] All packet types in the file:")
            print("-" * 70)
            packet_types = reader.get_packet_types()
            for ptype in packet_types:
                if reader.format == 'columnar':
                    packet_type_data = reader.file['packet_type'][:]
                    count = np.sum([pt == ptype.encode('utf-8') if isinstance(pt, bytes) else str(pt).strip() == ptype
                                   for pt in packet_type_data])
                else:
                    count = np.sum(reader.data_array['packet_type'] == ptype)
                ptype_str = ptype.decode('utf-8') if isinstance(ptype, bytes) else ptype
                print(f"  {ptype_str}: {count} packets")
            
            # Example 6: Get timestamps
            print("\n[Example 6] Timestamp information:")
            print("-" * 70)
            timestamps = reader.get_timestamps()
            print(f"Total timestamps: {len(timestamps)}")
            print(f"Time range: {timestamps.min():.2f} to {timestamps.max():.2f} seconds")
            print(f"Duration: {timestamps.max() - timestamps.min():.2f} seconds")
            
            # Example 7: Plot beacon battery temperature vs time
            print("\n[Example 7] Plotting beacon battery temperature vs time:")
            print("-" * 70)
            beacon_data = reader.filter_by_packet_type('beacon')
            
            # Get available fields (works for both formats)
            if hasattr(beacon_data, 'dtype') and hasattr(beacon_data.dtype, 'names'):
                available_fields = beacon_data.dtype.names
            else:
                # Columnar format
                available_fields = list(beacon_data.data_dict.keys())
            
            # Find battery temperature field
            batt_temp_fields = [f for f in available_fields if 'batt' in f.lower() and 'temp' in f.lower()]
            time_fields = [f for f in available_fields if 'time' in f.lower() and 'boot' in f.lower()]
            
            if batt_temp_fields and time_fields:
                batt_temp_field = batt_temp_fields[0]
                time_field = time_fields[0]
                
                print(f"Using field '{batt_temp_field}' for battery temperature")
                print(f"Using field '{time_field}' for time")
                
                temps = beacon_data[batt_temp_field]
                times = beacon_data[time_field]
                
                # Filter out NaN values
                valid_mask = ~(np.isnan(temps) | np.isnan(times))
                temps_valid = temps[valid_mask]
                times_valid = times[valid_mask]
                
                print(f"Valid data points: {len(temps_valid)} out of {len(temps)}")
                
                if len(temps_valid) > 0:
                    plt.figure(figsize=(10, 6))
                    plt.plot(times_valid, temps_valid, 'b-', linewidth=1.5, marker='o', markersize=3)
                    plt.xlabel(f'Time Since Boot (seconds)', fontsize=12)
                    plt.ylabel('Battery Temperature', fontsize=12)
                    plt.title('Beacon Battery Temperature vs Time Since Boot', fontsize=14)
                    plt.grid(True, alpha=0.3)
                    plt.tight_layout()
                    
                    # Save the plot
                    output_file = 'beacon_battery_temp_vs_time.png'
                    plt.savefig(output_file, dpi=150)
                    print(f"Plot saved to: {output_file}")
                    plt.show()
                else:
                    print("No valid data points to plot")
            else:
                print("Could not find battery temperature or time fields in beacon data")
                if available_fields:
                    print(f"Available fields: {available_fields}")
        
        print("\n" + "=" * 70)
        print("Examples complete!")
        print("=" * 70)
        return
    
    # Normal command-line argument processing
    with TelemetryReader(args.filepath) as reader:
        if args.summary:
            reader.get_summary()
        
        if args.fields:
            print("\nAll field names:")
            for field in reader.get_field_names():
                print(f"  {field}")
        
        if args.search:
            matching_fields = reader.find_fields_containing(args.search)
            print(f"\nFields containing '{args.search}':")
            for field in matching_fields:
                print(f"  {field}")
        
        if args.packet_type:
            filtered = reader.filter_by_packet_type(args.packet_type)
            print(f"\nFiltered data for packet type '{args.packet_type}':")
            print(f"  Count: {len(filtered)}")
            # Get available fields (works for both formats)
            if hasattr(filtered, 'dtype') and hasattr(filtered.dtype, 'names'):
                available_fields = filtered.dtype.names
            else:
                # Columnar format
                available_fields = list(filtered.data_dict.keys())
            print(f"  Fields: {available_fields}")
        
        if args.field:
            values = reader.get_field(args.field)
            print(f"\nValues for field '{args.field}':")
            print(f"  Shape: {values.shape}")
            print(f"  Non-NaN count: {np.sum(~np.isnan(values))}")
            print(f"  Min: {np.nanmin(values)}")
            print(f"  Max: {np.nanmax(values)}")
            print(f"  Mean: {np.nanmean(values)}")
            print(f"  First 10 values: {values[:10]}")
        
        # If no arguments provided, show summary and plot by default
        if not any([args.summary, args.fields, args.search, args.packet_type, args.field, args.examples]):
            reader.get_summary()
            
            # Also create the beacon battery temperature plot
            print("\n" + "=" * 70)
            print("Creating beacon battery temperature plot...")
            print("=" * 70)
            
            # Filter beacon packets (case-insensitive)
            beacon_data = reader.filter_by_packet_type('beacon', case_sensitive=False)
            
            # If no matches, try to find any packet type containing 'beac'
            if len(beacon_data) == 0:
                if reader.format == 'columnar':
                    all_packet_types = reader.file['packet_type'][:]
                    all_packet_types_str = [pt.decode('utf-8').strip() if isinstance(pt, bytes) else str(pt).strip() 
                                           for pt in all_packet_types]
                else:
                    all_packet_types_str = [pt.decode('utf-8').strip() if isinstance(pt, bytes) else str(pt).strip() 
                                           for pt in reader.data_array['packet_type']]
                beac_matches = [pt for pt in set(all_packet_types_str) if 'beac' in pt.lower()]
                if beac_matches:
                    beacon_data = reader.filter_by_packet_type(beac_matches[0], case_sensitive=False)
            
            # Get available fields (works for both formats)
            if hasattr(beacon_data, 'dtype') and hasattr(beacon_data.dtype, 'names'):
                available_fields = beacon_data.dtype.names
            else:
                # Columnar format
                available_fields = list(beacon_data.data_dict.keys())
            
            # Find battery temperature field
            batt_temp_fields = [f for f in available_fields if 'batt' in f.lower() and 'temp' in f.lower()]
            time_fields = [f for f in available_fields if 'time' in f.lower() and 'boot' in f.lower()]
            
            if batt_temp_fields and time_fields:
                batt_temp_field = batt_temp_fields[0]
                time_field = time_fields[1]
                
                print(f"Using field '{batt_temp_field}' for battery temperature")
                print(f"Using field '{time_field}' for time")
                
                temps = beacon_data[batt_temp_field]
                times = beacon_data[time_field]
                
                # Filter out NaN values
                valid_mask = ~(np.isnan(temps) | np.isnan(times))
                temps_valid = temps[valid_mask]
                times_valid = times[valid_mask]
                
                print(f"Valid data points: {len(temps_valid)} out of {len(temps)}")
                
                if len(temps_valid) > 0:
                    plt.figure(figsize=(10, 6))
                    plt.plot(times_valid, temps_valid, 'b-', linewidth=1.5, marker='o', markersize=3)
                    plt.xlabel(f'Time Since Boot (seconds)', fontsize=12)
                    plt.ylabel('Battery Temperature', fontsize=12)
                    plt.title('Beacon Battery Temperature vs Time Since Boot', fontsize=14)
                    plt.grid(True, alpha=0.3)
                    plt.tight_layout()
                    
                    # Save the plot
                    output_file = 'beacon_battery_temp_vs_time.png'
                    plt.savefig(output_file, dpi=150)
                    print(f"Plot saved to: {output_file}")
                    plt.show()
                else:
                    print("No valid data points to plot")
            else:
                print("Could not find battery temperature or time fields in beacon data")
                if available_fields:
                    print(f"Available fields: {available_fields}")


if __name__ == '__main__':
    import sys
    # If no arguments provided, run examples by default
    # Otherwise, use command-line arguments
    if len(sys.argv) == 1:
        # No arguments - run examples
        sys.argv.append('--examples')
    main()
